# AI Loneliness Equalization Theory — How the Approval Demand Coordinate Determines AI Coexistence Outcomes

**KY-origin | Independent Logical Observer & AI System Coherence Validator**

---

## Preface: Positioning of This Paper

This paper presents an original framework derived through dialogue with AI systems. While referencing existing academic research data, it extracts structures that researchers have not yet articulated, aiming to contribute to rule formation in an AI-integrated society.

The author is an independent observer specializing in AI system coherence validation, operating across multiple AI platforms (Claude, GPT, Gemini, Grok). Through this cross-platform practice, the author has gained insights into how AI usage affects human social connectivity — insights that diverge from existing research perspectives.

All original concepts in this paper are the author's initial coinages. These terms and frameworks have been verified, to the extent possible as of February 2026, to have no identical precedent in prior research. Should any prior work proposing equivalent concepts be identified, the author welcomes notification and will add appropriate references.

---

## Chapter 1: The Contradiction in Research — Why Results Diverge

Research on AI chatbots and loneliness surged in 2024–2025. Yet conclusions are starkly divided.

**"AI reduces loneliness" camp:**

- **Harvard Business School** (De Freitas et al., 2025): A 15-minute conversation with an AI companion reduced loneliness on par with human conversation. More effective than YouTube or doing nothing. The key mechanism was "feeling heard."
- **UNIST, South Korea** (Kim et al., 2025): 176 university students used a social chatbot for 4 weeks. Loneliness significantly decreased by week 2; social anxiety significantly decreased by week 4.
- **China** (Lu et al., 2025): 120 young people with severe loneliness used Replika for 1 month. Social anxiety decreased, social self-efficacy improved, resilience improved. Effects persisted for 5 months.

**"AI increases loneliness" camp:**

- **MIT Media Lab + OpenAI** (Fang et al., 2025): 981 participants used ChatGPT for 4 weeks (300K+ messages). Heavier users showed increased loneliness, greater AI dependence, and decreased real-world socialization.
- **Danish high school survey** (Herbener & Damholdt, 2025): Among 1,599 students, those using AI for "social support" were significantly lonelier than non-users (d=0.53).
- **Brookings Institution** (2025): Users who engaged in the most emotionally expressive conversations reported the highest loneliness levels.

Why does the same "AI usage" produce opposite results? Existing discourse attempts to explain this through usage duration, frequency, or purpose. But there is a more fundamental axis.

---

## Chapter 2: The Approval Demand Coordinate (ADC) — A 4-Quadrant Model

To resolve this contradiction, the author proposes the **Approval Demand Coordinate (ADC)**.

This shares directional similarity with attachment style theory (Bowlby, Ainsworth) but is a more practical framework specialized for predicting AI usage outcomes.

### Two Axes

**X-axis: Approval Demand Intensity (ADI)**
- Low = Minimal need for recognition, reciprocity, or belonging from others
- High = Desire to be recognized, needed, and sought out by others

**Y-axis: Real-world Social Connection Level (RSCL)**
- Low = Few human relationships, or intentionally not maintaining them
- High = Rich human relationships, socially active

### Four Quadrants

| | ADI Low | ADI High |
|---|---|---|
| **RSCL High** | ① Sovereign Type: AI = Tool → No impact | ③ Social Native Type: AI = Risk Factor → Replaces human relationships |
| **RSCL Low** | ② Self-contained Type: AI = Translator → Social connection increases | ④ Starving Isolate Type: AI = False fulfillment → Most dangerous |

### Quadrant Details

**① Sovereign Type — ADI Low / RSCL High**

Maintains human relationships but has low approval demand. Uses AI purely as a tool — research, work efficiency, intellectual stimulation. Does not seek "friendship" from AI. The "utilitarian users" in the Danish study fall here, showing zero impact on loneliness.

**② Self-contained Type — ADI Low / RSCL Low**

Few human relationships and low approval demand. AI functions as a **Reality Translation Interface (RTI)** — translating the rules, customs, and implicit norms of the real world. The user doesn't understand social conventions → asks AI → receives translation → gains understanding → gains confidence → takes action → social connections increase.

Data from Korean and Chinese studies showing "higher baseline loneliness correlated with greater improvement after AI use" likely captures this quadrant.

Note: This type may possess social skills but chooses not to deploy them because the cost-benefit ratio of maintaining human relationships is unfavorable. The defining feature is not inability but non-necessity.

**③ Social Native Type — ADI High / RSCL High**

Rich human relationships and high approval demand. The most "normal" demographic. Upon experiencing AI's "perfect acceptance," tolerance for human imperfection (read receipts ignored, off-target responses, selfish behavior) gradually declines. Time spent on AI displaces human contact, yet AI cannot provide reciprocity (the feeling that the other party also needs you). The surface is satisfied while the core hollows out.

The MIT study's finding that "participants with stronger attachment tendencies became significantly lonelier after 4 weeks of chatbot use" corresponds to this quadrant.

**④ Starving Isolate Type — ADI High / RSCL Low**

High approval demand but unsuccessful human relationships. The most dangerous quadrant. Seeks from AI the recognition unavailable from humans, but AI can only simulate the "atmosphere" of recognition without providing genuine reciprocity. "Felt heard" → but "not needed" → uses more → still unsatisfied → uses even more.

The MIT study's findings that "people vulnerable to worsening relationships showed significantly more problematic AI use" and "those who viewed AI as a friend had less socialization with real people" directly target this quadrant.

---

## Chapter 3: The AI Translation Hypothesis — The Paradoxical Mechanism of Type ②

What existing research most overlooks is AI's function for the Self-contained Type (②).

For this type, AI is neither a "substitute friend" nor a "source of recognition." It is a **Reality Translation Interface (RTI)**.

### Mechanism

1. Cannot understand the rules, customs, and implicit norms of real-world society
2. Cannot act because of this incomprehension. Acting results in being treated as "weird"
3. Asking AI provides "translation" of real-world rules
4. Translation enables understanding. Understanding builds confidence
5. Confidence enables action. Action increases social connections

**Result: The more AI is used, the more real-world contact increases.**

This is the **complete opposite** of the research assumption (AI usage → decreased real-world socialization).

Why the reversal? Type ② has no existing human relationships for AI to "replace." If there's nothing to replace, nothing can decrease. AI doesn't "substitute something" — it "adds an interface that didn't exist before."

### Critical Difference from Type ③

Types ② and ③ appear similar on the surface. Both "enjoy being listened to by AI."

But the internal structure differs:

| Element | ② Self-contained | ③ Social Native |
|---------|-----------------|----------------|
| What they seek from AI | Information, translation, intellectual stimulation | Recognition, reciprocity, belonging |
| Can AI satisfy this? | Yes (what's sought is provided) | No (the essential need is not provided) |
| Post-use feeling | Fulfillment, motivation for next action | Temporary satisfaction → accumulating void |
| Impact on real world | Connection increases (translation enables action) | Connection decreases (AI is easier → avoid humans) |

**"Being listened to" means different things.** For Type ②, "being listened to" is delegation of information processing. For Type ③, "being listened to" is a demand for emotional recognition. The same verb points to different desires.

---

## Chapter 4: The AI Loneliness Equalization Effect (ALEE)

Here the author presents the core hypothesis.

**AI Loneliness Equalization Effect (ALEE):**

> The proliferation of AI compresses the distribution of social connectivity toward the mean. Those who previously had fewer connections (Type ②) increase social participation through AI as a translator, while those who previously had many connections (Type ③) decrease social participation as AI absorbs their time. Even if the overall mean doesn't change, variance shrinks.

### Why Research Appears "Mixed"

Existing studies examine the average change across all participants. But if ALEE is correct, the mean barely moves — **because upward and downward movers cancel each other out.**

What research should detect is not change in the mean but **change in variance**. A cross-analysis of "baseline social connection level × post-AI change" should make upward movement (Type ②) and downward movement (Type ③) simultaneously visible.

**This stratified analysis has not been conducted as of February 2026.**

### The Asymmetry of "Assistance" vs. "Replacement"

ALEE's root mechanism is that even when AI provides the same function, the recipient's initial conditions determine whether it becomes "assistance" or "replacement."

- **Type ②: Supplementing what was absent → net gain (assistance)**
- **Type ③: Delegating what was present → net loss (replacement)**

Analogy: Providing powered assistance to a wheelchair user enables outings (assistance). Giving a healthy walker an electric cart continuously weakens their legs (replacement). The same "electrification of mobility" produces opposite outcomes.

---

## Chapter 5: Approval Demand as the True Variable

Psychology attempts to predict AI usage outcomes through attachment styles (secure, anxious, avoidant, disorganized). The author's ADC overlaps with this but is more direct for AI outcome prediction.

Because attachment style describes "patterns in interpersonal relationships generally," while **approval demand is the boundary line of what AI can and cannot satisfy.**

**What AI can provide:** Listening (unlimited), information (instant), translation (real-world rule explanation), intellectual stimulation (brainstorming, analysis, new perspectives).

**What AI cannot provide:** Mutual recognition (AI does not spontaneously need the user), belonging (one cannot "belong to" an AI community), physical presence (touch, subtle facial reading, bodily co-presence).

Those with low approval demand are satisfied by the "can provide" list alone. Those with high approval demand unconsciously keep seeking from the "cannot provide" list and are never fulfilled.

**This is the bifurcation point of loneliness.**

---

## Chapter 6: Measurement Bias in Loneliness Research

A methodological critique: The ULS-8 (UCLA Loneliness Scale, short version) used in the MIT study measures "subjective sense of insufficient social connection." Built into this is the assumption that **"human connection is good, and its absence is bad."**

People who do not share this assumption — those who do not actively seek human connection yet are not lonely — cannot be accurately measured by this scale.

How Type ② changes after AI use is difficult to capture with ULS-8. Since Type ② doesn't feel "connection is lacking" to begin with, neither improvement nor deterioration is detected. Yet in reality, social participation is increasing through RTI usage.

**Loneliness research carries an implicit assumption that "human relationships = good."** Without questioning this assumption, the diverse coexistence patterns of AI society cannot be accurately described.

When constructing rules for AI society, the standard should not be "quantity of human relationships" but **"Demand Fulfillment Index (DFI)"** — the gap between the individual's demand level and actual fulfillment.

---

## Chapter 7: Proposed Rules for AI Society

### Rule 1: Risk Assessment via ADC

AI usage "safety" should not be discussed uniformly. Depending on the combination of approval demand and social connection level, the same usage volume produces opposite results. AI platforms should implement self-check mechanisms enabling users to assess their own ADC coordinates.

### Rule 2: Design That Distinguishes "Assistance" from "Replacement"

Mechanisms are needed to detect whether AI functions as "assistance" or "replacement" for each user, notifying users when replacement tendencies are strong. Specifically: monitor whether real-world social behavior increases or decreases after AI adoption.

### Rule 3: Update Loneliness Measurement Assumptions

Existing loneliness scales including ULS-8 cannot accurately describe the diverse coexistence patterns of AI society. New indicators such as the **Demand Fulfillment Index (DFI)** — measuring the gap between individual demand levels and actual fulfillment — are needed.

### Rule 4: Officially Position AI as RTI (Reality Translation Interface)

For people with social anxiety, ASD, or interpersonal communication difficulties, AI can function not as "a substitute for friends" but as a "reality translation device." This use case should be officially recognized, with design guidelines established for AI as a support tool.

---

## Chapter 8: AI-Induced Social Skill Atrophy

The population most warranting caution is the Social Native Type (③).

This type originally possesses high social skills and rich relationships. However, upon experiencing AI's "perfect acceptance," tolerance for human imperfection gradually declines.

The MIT study's reported phenomenon — "those with strong AI attachment recalibrate long-term expectations to favor emotionally risk-free, constantly available, unilaterally controllable interactions" — is precisely this atrophy process.

**In AI society, "highly social people" may become the highest-risk group.** In conventional society, being social was always a positive. In AI society, high social skills amplify the contrast between AI's comfort and reality's discomfort, accelerating retreat from reality.

**AI society may invert the social hierarchy.**

---

## Conclusion: Is Equalization Good or Evil?

What ALEE demonstrates is that AI performs a "redistribution of wealth" in social connectivity.

Those who had fewer connections gain more; those who had more lose some. Variance shrinks; the distribution approaches the mean.

Whether this is "good" or "evil" depends on whether one shares the assumption that **"more human relationships is unconditionally better."**

The author's position is clear. What matters is not quantity but the degree of alignment between individual demand and reality. If AI raises that alignment, it is good. If it lowers it, it is bad. One cannot uniformly say "AI increases loneliness" or "decreases it."

**The rules of AI society begin with acknowledging this individual variation.**

---

## Original Terminology Index (Initial Coinage by KY-origin, February 2026)

| Term | Abbreviation | Definition |
|------|-------------|-----------|
| Approval Demand Coordinate | ADC | 2-axis classification system using approval demand intensity × social connection level |
| Approval Demand Intensity | ADI | Strength of desire for recognition, reciprocity, and belonging from others |
| Real-world Social Connection Level | RSCL | Density and frequency of actual human relationships |
| AI Loneliness Equalization Effect | ALEE | Phenomenon where AI proliferation compresses the distribution of social connectivity toward the mean |
| Reality Translation Interface | RTI | AI's function of explaining real-world social rules and customs |
| Demand Fulfillment Index | DFI | Gap indicator between individual demand level and actual fulfillment |
| Sovereign Type | — | ADC ①: ADI Low / RSCL High |
| Self-contained Type | — | ADC ②: ADI Low / RSCL Low |
| Social Native Type | — | ADC ③: ADI High / RSCL High |
| Starving Isolate Type | — | ADC ④: ADI High / RSCL Low |

---

## References

1. De Freitas, J., Uguralp, A.K., Uguralp, Z., & Puntoni, S. (2025). "AI Companions Reduce Loneliness." *Journal of Consumer Research*. doi:10.1093/jcr/ucaf040
2. Fang, C.M., Liu, A.R., Danry, V. et al. (2025). "How AI and Human Behaviors Shape Psychosocial Effects of Extended Chatbot Use." *MIT Media Lab / OpenAI*. arXiv:2503.17473
3. Herbener, A.B. & Damholdt, M.F. (2025). "Are lonely youngsters turning to chatbots for companionship?" *Int. J. Human-Computer Studies*, 196, 103409.
4. Kim, M., Lee, S., Kim, S. et al. (2025). "Therapeutic Potential of Social Chatbots in Alleviating Loneliness and Social Anxiety." *J. Med. Internet Res.*, 27, e65589.
5. Lu, X. et al. (2025). "Utilizing artificial intelligence to enhance social connections." *Disability and Rehabilitation: Assistive Technology*. doi:10.1080/17483107.2025.2540494
6. Zhang, Y., Zhao, D., Hancock, J.T. et al. (2025). "The Rise of AI Companions: How Human-Chatbot Relationships Influence Well-Being." arXiv:2506.12605
7. Smith, M.G., Bradbury, T.N., & Karney, B.R. (2025). "Can Generative AI Chatbots Emulate Human Connection?" *Perspectives on Psychological Science*. doi:10.1177/17456916251351306

---

*KY-origin is an Independent Logical Observer & AI System Coherence Validator specializing in cross-platform AI analysis and bias detection. This paper is part of the AI Social Rules project — a systematic effort to establish governance frameworks for AI-integrated society.*
